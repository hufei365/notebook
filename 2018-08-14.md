[原文地址：Backpressuring in Streams](https://nodejs.org/en/docs/guides/backpressuring-in-streams/)

## Stream中的背压（Backpressure）

backpressure是数据处理期间一般会出现问题。 主要意思就是数据传输期间，缓冲区会产生一定量的数据累积。如果数据的接收端具有复杂的操作，或者由于某种原因而变慢时，来自输入端的数据会逐渐累积，产生一些问题，例如阻塞。

要解决这个问题，必须有一个委托系统来确保数据从一个源到另一个源平滑地传输。不同的社区针对这个问题已经有了他们各自的解决方案。Unix管道和TCP套接字就是这方面的范例，并且这通常被称为流控制。在Node.js中，流被采用作为这个解决方案。

本指南的目的是进一步详细说明背压是什么，以及更详细地说明在Node.js的源代码中如何用流解决这个问题。本指南的第二部分将介绍一些最佳实践，以确保在实现流时，应用程序的代码是比较安全的和高性能的。

假设你对在Node.js中的backpressure，Buffer以及EventEmitters已经有一点点的熟悉。并且有一些关于Stream的经验。如果您还没有阅读这些文档，那么首先查看一下API文档是一个比较好的主意，因为它有助于在阅读本指南时扩展您的理解。

### 数据处理的问题

在计算机系统中，数据通过管道（pipes），套接字（sockets）和信号从一个进程传输到另一个进程。在Node.js中，有一种类似的机制 Stream。Stream 是很棒的！它为Node.js做了很多事情，几乎内部代码库的每个部分都使用该模块。作为开发人员，我们鼓励您使用它们！

``` javascript
const readline = require('readline');

// process.stdin and process.stdout are both instances of Streams
const rl = readline.createInterface({
	input: process.stdin,
	output: process.stdout
});

rl.question('Why should you use streams? ', (answer) => {
	console.log(`Maybe it's ${answer}, maybe it's because they are awesome! :)`);

	rl.close();
});

```

通过比较Node.js Stream实现的内部系统工具，可以证明通过流实现backpressure机制是一个很好的优化示例。

在一种情况下，我们将使用一个大文件（大约〜9gb）并使用熟悉的[zip(1)](https://linux.die.net/man/1/zip)工具对其进行压缩。

``` shell
$ zip The.Matrix.1080p.mkv
```

虽然这需要几分钟才能完成，但在另一个shell中，我们可能会运行一个带有Node.js模块的脚本，该模块zlib包含另一个压缩工具gzip(1)。

``` javascript
const gzip = require('zlib').createGzip();
const fs = require('fs');

const inp = fs.createReadStream('The.Matrix.1080p.mkv');
const out = fs.createWriteStream('The.Matrix.1080p.mkv.gz');

inp.pipe(gzip).pipe(out);
```

要测试结果，请尝试打开每个压缩文件。通过`zip(1)`工具压缩的文件在解压缩时会发现文件已损坏，而通过Stream完成的压缩，在解压缩时不会出错。

注意：在上面的示例中，我们使用`.pipe()`从一端到另一端获取数据。但是，请注意没有附加正确的错误处理程序。如果无法正确接收大量数据，则不会销毁Readable源或 gzip流。pump是一个实用工具，如果其中一个流失败或关闭，将销毁管道中的所有流，在这种情况下这种处理是必须的！

pump只有Nodejs 8.x或更早版本才需要，因为在Node10.x或更高版本中，pipeline被引入，用于替换pump。这是一种模块方法，用于管理流转发错误和正确清理流并在管道完成时提供回调。

以下是使用管道的示例：

``` javascript
const { pipeline } = require('stream');
const fs = require('fs');
const zlib = require('zlib');

// Use the pipeline API to easily pipe a series of streams
// together and get notified when the pipeline is fully done.
// A pipeline to gzip a potentially huge video file efficiently:

pipeline(
  fs.createReadStream('The.Matrix.1080p.mkv'),
  zlib.createGzip(),
  fs.createWriteStream('The.Matrix.1080p.mkv.gz'),
  (err) => {
    if (err) {
      console.error('Pipeline failed', err);
    } else {
      console.log('Pipeline succeeded');
    }
  }
);

```

您还可以调用promisify管道将其与async/await一起使用：

``` javascript
const stream = require('stream');
const fs = require('fs');
const zlib = require('zlib');

const pipeline = util.promisify(stream.pipeline);

async function run() {
    try {
        await pipeline(
            fs.createReadStream('The.Matrix.1080p.mkv'),
            zlib.createGzip(),
            fs.createWriteStream('The.Matrix.1080p.mkv.gz'),
        );
        console.log('Pipeline succeeded');
    } catch (err) {
        console.error('Pipeline failed', err);
    }
}
```

### 太多的数据，太快了

有些情况下，Readable流可能会比Writable流更快地提供数据 ———— 远远超过使用者处理数据的速度！

当发生这种情况时，所有数据块将会排队等待数据消费者处理。此时写入队列将变得越来越长，在整个过程完成之前，这些数据必须保存在内存中。

写入磁盘比从磁盘读取慢得多，因此，当我们尝试压缩文件并将其写入硬盘时，会发生backpressure，因为写入磁盘的速度无法跟上读取速度。请阅读：

``` shell
// Secretly the stream is saying: "whoa, whoa! hang on, this is way too much!"
// Data will begin to build up on the read-side of the data buffer as
// `write` tries to keep up with the incoming data flow.
inp.pipe(gzip).pipe(outputFile);
```

这就是backpressure机制很重要的原因。如果没有backpressure系统，该过程将耗尽系统的内存，这会显著影响其他进程，并独占系统的大部分资源直到完成。

这导致了一些事情：


- 减慢其他所有当前流程
- 垃圾收集器过载
- 内存资源耗尽
- 
在下面的例子中，我们将取出返回值的的 `.write()`功能，将其更改为true，这样可有效禁用在Node.js的核心backpressure支持。在对'modified'二进制文件的任何引用中，我们讨论的是在node没有`return ret;`行的情况下运行二进制文件，而是使用替换的`return true;`。

### GC(Garbage Collection)上的额外压力

我们来浏览下基准测试。使用上面的相同示例，我们进行了一些时间试验，以获得两个二进制文件处理的平均时间。

```
   trial (#)  | `node` binary (ms) | modified `node` binary (ms)
=================================================================
      1       |      56924         |           55011
      2       |      52686         |           55869
      3       |      59479         |           54043
      4       |      54473         |           55229
      5       |      52933         |           59723
=================================================================
average time: |      55299         |           55975
```

两者都需要大约一分钟才能运行，因此根本没有太大差别，但让我们仔细看看以确认我们的怀疑是否正确。我们使用Linux工具[dtrace](http://dtrace.org/blogs/about/)来评估V8垃圾收集器的情况。

GC（垃圾收集器）测量时间表示垃圾收集器完成单次扫描所需的完整周期。

```
approx. time (ms) | GC (ms) | modified GC (ms)
=================================================
          0       |    0    |      0
          1       |    0    |      0
         40       |    0    |      2
        170       |    3    |      1
        300       |    3    |      1

         *             *           *
         *             *           *
         *             *           *

      39000       |    6    |     26
      42000       |    6    |     21
      47000       |    5    |     32
      50000       |    8    |     28
      54000       |    6    |     35

```

虽然两个过程开始时相同并且似乎以相同的速率运行GC，但很明显，在有背压系统的环境中，适当工作几秒钟后，GC扫描周期基本分布在4-8毫秒之内，且一直持续到数据传输结束。

但是，在没有背压系统的条件下，V8垃圾收集开始变慢。普通二进制文件 在一分钟内GC运行大约75次，而修改后的二进制文件仅执行了36次。

这是由于内存使用量增加而慢慢累积出的问题。随着数据传输，在没有背压系统的情况下，每个块传输使用更多内存。

分配的内存越多，GC在一次扫描中需要处理的空间就越大，GC需要判断是否可以释放的空间的也就越大，并且在更大的内存空间中扫描隔离开的指针将消耗更多的计算能力。

### 内存耗尽

为了确定每个二进制文件的内存消耗，我们通过`/usr/bin/time -lp sudo ./node ./backpressure-example/zlib.js` 单独为每个进程计时。

这是普通二进制文件的输出：

```
Respecting the return value of .write()
=============================================
real        58.88
user        56.79
sys          8.79
  87810048  maximum resident set size
         0  average shared memory size
         0  average unshared data size
         0  average unshared stack size
     19427  page reclaims
      3134  page faults
         0  swaps
         5  block input operations
       194  block output operations
         0  messages sent
         0  messages received
         1  signals received
        12  voluntary context switches
    666037  involuntary context switches
```

虚拟内存占用的最大字节大小约为87.81 mb。

现在改变`.write()`的返回值，我们得到：

```
Without respecting the return value of .write():
==================================================
real        54.48
user        53.15
sys          7.43
1524965376  maximum resident set size
         0  average shared memory size
         0  average unshared data size
         0  average unshared stack size
    373617  page reclaims
      3139  page faults
         0  swaps
        18  block input operations
       199  block output operations
         0  messages sent
         0  messages received
         1  signals received
        25  voluntary context switches
    629566  involuntary context switches
```

虚拟内存占用的最大字节大小约为1.52 gb。

如果没有流来委托背压，则会分配更大的内存空间 - 同一过程之间存在巨大的差异！

此实验显示了Node.js优化且经济高效的背压机制如何适用于您的计算系统。现在，让我们分析一下它是如何工作的！

## 背压如何解决这些问题？

有不同的方法将数据从一个进程传输到另一个进程。在Node.js中，有一个名为`.pipe()`的内置函数, 它在其他包中也可以使用！但最终，在这个过程的本质上，我们有两个独立的组件：数据来源者和消费者。

当`.pipe()`从数据源调用时，它向消费者发出信号，表明存在要传输的数据。管道功能会在特定的事件触发时，关闭背压系统。

在Node.js中，数据源是一个Readable流，而消费者是 Writable流（这些都可以与一个[Duplex](https://nodejs.org/api/stream.html#stream_duplex_and_transform_streams)或一个[Transform](https://nodejs.org/api/stream.html#stream_duplex_and_transform_streams)流互换，但这超出了本指南的范围）。

该背压被触发的时刻可以精确缩小到Writable的`.write()`函数一个返回值。当然，该返回值由几个条件决定。

在数据缓冲区已超过[highWaterMark](https://nodejs.org/api/stream.html#stream_buffering)或写入队列当前正忙的情况下，`.write()`将返回false。

当false被返回时，背压系统启动。它将暂停传入Readable流发送的任何数据并等待消费者再次准备就绪。清空数据缓冲区后，`.drain()` 将发出一个事件并恢复数据流的传入。

队列完成后，背压将允许再次发送数据。正在使用的内存空间将自行释放并为下一批数据做好准备。

这有效地允许在任何给定时间使用固定量的存储器用于`.pipe()`功能。没有内存泄漏，没有无限缓冲，垃圾回收器只需要处理内存中的一个有限的特定区域！

那么，如果背压如此重要，为什么你（可能）没有听过它？答案很简单：Node.js自动为您完成了所有这些工作。

这太棒了！但是当我们试图了解如何实现我们自定义的流时，这就不是那么好了。

注意：在大多数计算机中，有一个字节大小可以确定缓冲区何时已满（在不同的计算机上会有所不同）。Node.js允许您设置自己的自定义highWaterMark，但通常，默认设置为16kb（对于objectMode流，为16384或16）。在您可能想要提高该值的情况下，请继续使用它，但请谨慎使用！

### `.pipe()`的生命周期

为了更好地了解反压，这里是一个Readable流被管道输送到一个Writable流的生命周期流程图：

```
                                                     +===================+
                         x-->  Piping functions   +-->   src.pipe(dest)  |
                         x     are set up during     |===================|
                         x     the .pipe method.     |  Event callbacks  |
  +===============+      x                           |-------------------|
  |   Your Data   |      x     They exist outside    | .on('close', cb)  |
  +=======+=======+      x     the data flow, but    | .on('data', cb)   |
          |              x     importantly attach    | .on('drain', cb)  |
          |              x     events, and their     | .on('unpipe', cb) |
+---------v---------+    x     respective callbacks. | .on('error', cb)  |
|  Readable Stream  +----+                           | .on('finish', cb) |
+-^-------^-------^-+    |                           | .on('end', cb)    |
  ^       |       ^      |                           +-------------------+
  |       |       |      |
  |       ^       |      |
  ^       ^       ^      |    +-------------------+         +=================+
  ^       |       ^      +---->  Writable Stream  +--------->  .write(chunk)  |
  |       |       |           +-------------------+         +=======+=========+
  |       |       |                                                 |
  |       ^       |                              +------------------v---------+
  ^       |       +-> if (!chunk)                |    Is this chunk too big?  |
  ^       |       |     emit .end();             |    Is the queue busy?      |
  |       |       +-> else                       +-------+----------------+---+
  |       ^       |     emit .write();                   |                |
  |       ^       ^                                   +--v---+        +---v---+
  |       |       ^-----------------------------------<  No  |        |  Yes  |
  ^       |                                           +------+        +---v---+
  ^       |                                                               |
  |       ^               emit .pause();          +=================+     |
  |       ^---------------^-----------------------+  return false;  <-----+---+
  |                                               +=================+         |
  |                                                                           |
  ^            when queue is empty     +============+                         |
  ^------------^-----------------------<  Buffering |                         |
               |                       |============|                         |
               +> emit .drain();       |  ^Buffer^  |                         |
               +> emit .resume();      +------------+                         |
                                       |  ^Buffer^  |                         |
                                       +------------+   add chunk to queue    |
                                       |            <---^---------------------<
                                       +============+
```

注意：如果要设置管道以将一些流链接在一起来操作数据，则很可能正在实现[Transform](https://nodejs.org/api/stream.html#stream_duplex_and_transform_streams) 流。

在这种情况下，您的Readable流的输出将 输入到 Transform或Writable。

```
Readable.pipe(Transformable).pipe(Writable);
```

背压将自动应用，但请注意，`[Transform](https://nodejs.org/api/stream.html#stream_duplex_and_transform_streams)`的输入和输出highWaterMark都可能被修改，这会影响背压系统。

## Backpressure 指南

从Node.js v0.10开始，Stream该类提供了修改`.read()`或`.write()`函数行为的能力（低版本的通过使用`._read()`和 `._write()`）。

有一些关于 `[Readable streams](https://nodejs.org/docs/latest/api/stream.html#stream_implementing_a_readable_stream)` 和 `[Writable streams](https://nodejs.org/docs/latest/api/stream.html#stream_implementing_a_writable_stream)`实现机制的文档 。我们假设您已阅读过这些内容，下一节将更深入一些。

### 实现自定义流时要遵守的规则

`Stream`的黄金法则始终是 **尊重背压**。最佳实践的构成是非矛盾的实践。只要您小心避免与内部背压支持相冲突的行为，您就可以确定您遵循良好做法。

